\chapter{Conclusions and perspectives}
\label{chap:discussion}

\begin{flushright}
\begin{small}
\textit{In the study of nature, as in the practice of art, it is not given to man to achieve the goal without leaving a trail of dead ends he had pursued.}\\ \\
Baron Louis Bernard Guyton de Morveau
\end{small}
\end{flushright}

\section{Summary of the results}

The initial objective of this PhD work was to study the evolution of all glaciers in the French Alps from the last decades of the 20$^{th}$ century until the end of the 21$^{st}$ century, and to explore the impact of their retreat in the hydrological budget of the Rhône river catchment. However, this initial objective was adapted following the exploration of machine learning methods for glacier mass balance simulation at the end of the first year of the project. My strong interest in these rather unexploited methods in glaciology led to important changes in the results, largely expanding the efforts dedicated on methods, and reducing the amount of results on hydro-glaciological modelling. Consequently, the resulting scientific questions that were addressed during these three years also evolved. In this section, I will address each one of these questions, giving an overview of the results and determining the accomplished objectives as well as the remaining challenges.

\subsubsection{Question 1 - Can deep learning be applied to model annual glacier mass balance changes at a regional scale? What are the benefits of using nonlinear deep learning models compared to linear machine learning?}

In Chapter 2, based on a paper published in \textit{The Cryosphere} journal, we introduced, to our knowledge, the first effort ever to apply deep learning to simulate glacier evolution. A new open-source regional glacier evolution model (ALPGM) was developed, whose main novelty was a mass balance component based on machine learning. Our work showed promising results, proving that deep learning can be successfully used to simulate glacier mass balance. A detailed comparison between linear machine learning methods and deep learning highlighted how important nonlinearities are captured by deep learning. Since both the climate and glacier systems are known to be highly nonlinear (e.g., the glacier mass balance response to temperature), this resulted in an improved performance from deep learning models, with an improved accuracy (RMSE) of up to +58\% and explained variance (r$ ^{2}$) of up to +108\%. Moreover, despite using a rather small dataset of annual mass balance data, we proved that by rigorously cross-validating the models, deep learning can still learn from "small data" without overfitting. Spatiotemporal data demands that the independence of both dimensions have to be respected during cross-validation. We devised different types of cross-validation which allowed an accurate evaluation of the performance of models in the spatial and temporal dimensions, while fully utilizing the whole dataset to train the models. 

\subsubsection{Question 2 - What are the annual glacier changes of all glaciers in the French Alps for the last half century?}

In Chapter 3, based on a paper published in the \textit{Earth System Science Data} journal, we applied the deep learning methods developed in Chapter 2 to the reconstruction of annual glacier-wide MB series of all glaciers in the French Alps (N=661) between 1967 and 2015. Our results showed that French alpine glaciers went through slightly negative MB rates from the late 1960s and during the 1970s (-0.44 m w.e. a$^{-1}$). Then, during the 1980s  their MB was almost stable (-0.16 m.w.e. a$^{-1}$, with several positive years), before becoming more negative from the 1990s (-0.71 m.w.e. a$^{-1}$). Their MB rates became remarkably more negative from the 2000s (-1.18 m.w.e. a$^{-1}$), especially after the famous heatwave from the year 2003. This year established an inflection point, from which MB became increasingly negative up to -1.26 m.w.e. a$^{-1}$ for the first half of the 2010s. Important differences were found between massifs, with the Mont-Blanc massif showing the least negative MB, and the Chablais massif presenting the highest losses. We showed how this method correctly captured the interannual variability of the glacier-wide MB signal of glaciers in the French Alps, mostly driven by climate, and how it also captured differences between glaciers with various topographical characteristics. 

\subsubsection{Question 3 - How will French alpine glaciers evolve during the 21st century? How does glacier retreat affect the climate signal on glaciers? What are the main factors that determine glacier survival in the French Alps?}

\blindtext

\subsubsection{Question 4 - What are the current limitations in the representation of glaciers in hydrological models in France? How can we improve this?}

Current hydrological models used in the France by territorial stakeholders or hydro-power managers generally suffer from a simplified representation of glaciers as static ice reservoirs. This is highly problematic in the current context of rapid glacier retreat in the French Alps. Glacio-hydrological models need to accurately represent glacier evolution in order to take into account the progressive changes in hydrologic regime, seasonality and glacier runoff. These changes can drive important social and environmental impacts in the French Alps, which demand adequate tools to perform accurate glacio-hydrological projections. In this work, we introduced an updated glacier module for the well-established J2K hydrological model \citep{krause_quantifying_2002}, capable of representing the daily evolution of glaciers. This approach is based on prescribed annual glacier extents, that can proceed from any glacier evolution model. We validated this method in the Arvan partially glacierized catchment, located in the Grandes Rousses massif, for which we also assessed the effects of glacier retreat on the recent past. With this new enhanced representation of glaciers in the J2K hydrological model, we have set the means for future glacio-hydrological studies in the Rhône river catchment to assess the hydro-ecological impacts of glacier retreat. Moreover, the glacier evolution data generated by ALPGM can potentially be used as input to other hydrological models (e.g., MORDOR, GR), in order to introduce glacier evolution as it has been done for J2K.

\section{Perspectives on future research venues}

This PhD work served to bring attention to the benefits of using deep learning for regression problems in glacier evolution modelling. At the beginning of this PhD, to my knowledge, there were no papers published using deep learning on glaciers. For the AGU Fall Meeting 2019, a new session on machine learning, artificial intelligence (AI) and remote sensing on the cryosphere was created for the first time. This session served to catalyse all the current research in this sub-field, with many papers published around that period. For the first time, researchers working on these topics were able to exchange, discuss and even collaborate in bringing new methods to different applications in glaciology. This experience was followed by another session on machine learning and AI for glaciology at the EGU General Meeting 2020, which despite the virtual format due to the global COVID-19 crisis, further displayed the huge potential of these applications from a wide range of glaciological problems. Machine learning and data science in glaciology is still a very novel field, but many promising applications are being presented by the day \citep[e.g.][]{leong_deepbedmap_2020, brinkerhoff_constraining_2020}, showing multiple directions for the sub-field to evolve towards. 

So far, as it was shown in these two previous sessions at AGU and EGU, the great majority of efforts have been focused on classification problems. New satellite imagery, with ever improving spatial and temporal resolution, is being successfully exploited by deep learning methods to automatically extract glacier fronts in Greenland and Antarctica \citep[e.g.][]{lea_google_2018,baumhoer_automated_2019,mohajerani_detection_2019, zhang_automatically_2019} and supraglacial lakes \cite[e.g.][]{yuan_automatic_2020}. The validation of these approaches is more straightforward than for regression problems, mainly demanding the manual delineation or classification of geometric features in satellite imagery. Moreover, in such applications where interpretability is not a concern, the full predictive power of convolutional neural networks (NNs) can be unleashed. Conversely, regression problems in glaciology remain highly unexplored, due to the inherent complexity of correctly representing physical processes with NNs. This brings us to the last scientific question of this PhD work.

\subsubsection{Question 5 - What are the caveats of the deep learning modelling approach used in this work? What improvements are needed to overcome these limitations for glaciological studies?}

The work of this PhD showed how deep learning models can be extremely challenging to interpret. We attempted to partially do so by training a parallel linear machine learning model (Lasso) with the same dataset, and by thoroughly cross-validating it respecting spatiotemporal structures in data. Nonetheless, these represented just approximations of what the true underlying model actually is, and raised many questions on how to address these issues. 

Fortunately, in the last years enormous progress has been made towards interpretable machine learning and particularly interpretable NNs. NNs are universal function approximators, meaning that any sufficiently large NN can approximate any nonlinear function with a finite set of parameters \citep{winkler_performance_2017}. This remarkable predicting power comes at the cost of very low interpretability, requiring deep changes in the way we design NNs. In order to represent a partially known physical process with a NN, two main approaches are being proposed nowadays: (1) NNs are optimized following a certain loss function, which determines how they learn and update the weights of the different connections between neurons. By consciously modifying a NN's architecture, one can constrain the way NNs learn based on prior knowledge. The most prominent way so far has been to encode prior knowledge, in the form of differential equations (DEs), as the loss function of a NN. By doing so, the learning of NNs is constrained following currently known equations \citep{raissi_physics_2017,karpatne_physics-guided_2018}. Additionally, by using specific architectures that suit the specificities of a given physical process, the learning can be further constrained, limiting or enhancing the interactions between certain input predictors \citep{karpatne_theory-guided_2017}. Such an approach enables an equation-guided learning, but does not fully deal with the "black box" consequences on interpretability. (2) Another way of looking at this problem is that, instead of trying to constrain the learning of NNs, NNs can be reduced to the smallest possible entities, in order to decrease their complexity to the point they can be interpreted. This radically different approach is currently showing very exciting results. The beauty of this approach resides on the fact that it manages to create hybrid models, mixing a classical physical approach based on DEs with the phenomenal predictive power of NNs to optimize unknown parameters \citep{rackauckas_universal_2020}. The main structure of such a model remains a DE, which is augmented with NNs that replace the unknowns parameters. New methods enable the optimization of DEs combined with NNs, allowing the NNs to produce nonlinear functions that optimize the unknowns following an equation determined by the DE \citep{raissi_physics_2017,rackauckas_universal_2020,bradbury_jax_2020}. Since these "small" NNs are based on just one or two input predictors, their output values can be sampled using Monte Carlo methods at their input. By applying a sparse regression on its outputs, one can obtain a mathematical representation of the nonlinear function learnt by the NN \citep{brunton_discovering_2016}. This mathematical representation of NNs can be used to interpret them, while suggesting reformulations in the currently known equations used in the model \citep{rackauckas_universal_2020}. 

The sub-field of glacier machine learning and data science is ripe for progress, and many innovative studies are offering new perspectives on how to improve our understanding of glacier processes with models. Not all solutions go through NNs, as a study by \citet{werder_bayesian_2019} recently showed. They applied a Bayesian inference inverse model to estimate glacier ice thickness. By reusing an already established model by \citet{huss_distributed_2012} describing the ice thickness distribution of glaciers, they were able to improve the assimilation of observations for the optimization of model parameters, while performing a detailed assessment of their uncertainties and errors. \citet{rounce_quantifying_2020} followed a similar approach with a regional glacier evolution modelling study of MB in High Mountain Asia. The use of Bayesian inference provided new insights on the main sources model uncertainty, further highlighting the benefits of transitioning from deterministic to probabilistic modelling. More recently, a study by \citet{brinkerhoff_constraining_2020} took this approach to another level by applying it to a surrogate model based on deep learning. Bayesian inference can be computationally expensive, and its application to highly complex models involving several parameters, such as a 3D spatially-explicit hydrological model coupled with ice dynamics, is not feasible for now. In this study, they bypassed this limitation by substituting this model with a "black box" NN, producing an equivalent solution at a fraction of the computational cost. This surrogate model allowed the use of Bayesian inference in order to correctly estimate parameter uncertainties and errors. Such diverse approaches display new ways of tackling glaciological modelling, that can provide major changes in our understanding of glacier processes and their drivers. 

These new methods offer a great perspective to overcome the main limitations of our current glacier evolution modelling approach. By reusing currently known equations of glacier processes, such as the Shallow Ice Approximation \citep{hutter_theoretical_1983} or enhanced temperature-index or surface energy balance models, we can aim at building new methods on top of the most reliable theoretical bases in our field. This offers the possibility to optimize and potentially reformulating these equations, in order to exploit data using NNs in an interpretable manner, creating knowledge that can be reused by the whole glaciological community. During the last year of my PhD, I have been thinking about and developing these ideas, gathering them in the form of a postdoc proposal. With it, I propose to use hybrid models composed by differential equations and NNs to simulate glacier evolution at a large scale. Such an approach can potentially enable a detailed interpretation of specific glacier processes (e.g. ice dynamics or glacier sliding) from parameters optimized by NNs, which could be taken into account by reformulating currently known equations. I hope to be able to continue investigating this line of research, as I keep learning from these two fascinating research fields that are glaciology and machine learning. 

